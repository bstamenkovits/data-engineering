{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86b53c8e",
   "metadata": {},
   "source": [
    "# **Introduction to PySpark**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f60ea9",
   "metadata": {},
   "source": [
    "## Spark\n",
    "Spark is a platform that makes it easier to work with large datasets by spreading out the data and computations across **clusters**, containing multiple **nodes**. Each node is like a small computer, that can focus purely on a subset of the data. This way the total data can be computed in **parallel**\n",
    "\n",
    "### Spark in Python\n",
    "A spark cluster consists of one **master** node which controls multiple **worker** nodes. In practice the cluster is hosted on a remote machine (e.g. in Azure or DataBricks)\n",
    "\n",
    "Creating a connection to the spark cluster is done by using the `SparkContext` class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92c07528-6b9d-4e4a-a84f-ca3659627c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local[*] appName=pyspark-shell>\n",
      "3.5.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "sc = SparkContext()\n",
    "\n",
    "print(sc)\n",
    "print(sc.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68952136-d73f-4a82-a992-06f84b1860e2",
   "metadata": {},
   "source": [
    "### DataFrames\n",
    "The core data structure Spark uses is the **Resilient Distributed Dataset (RDD)**. This is a low level object that allows Spark to distribute data over its various nodes in the cluster. **DataFrames** are an abstraction built ontop of RDDs that make it easier to work with the data, for complex operations they can even be faster than RDDs.\n",
    "\n",
    "Spark DataFrames are similar to Pandas DataFrames, especially in their syntax. There are some key difference though\n",
    "|1|2|\n",
    "|-|-|\n",
    "|2|3|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0504e10-0c79-42db-97dd-05c0a560c624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c5dd1cc-ec38-4325-a9dd-257ae53d2be3",
   "metadata": {},
   "source": [
    "Calculate pi using spark cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "158076f0-3bc9-4c24-a128-72793c690136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi is roughly  3.1415276\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from pyspark import SparkContext\n",
    "\n",
    "sc = SparkContext()\n",
    "\n",
    "def inside(_):\n",
    "    x, y = random.random(), random.random()\n",
    "    return x*x + y*y < 1\n",
    "\n",
    "n_samples = 100000000\n",
    "count = sc.parallelize(range(0, n_samples)).filter(inside).count()\n",
    "pi = 4 * count / n_samples\n",
    "\n",
    "print(\"Pi is roughly \", pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c146f7a-95e2-4f37-aaa7-99a4b12de765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local[*] appName=pyspark-shell>\n",
      "3.5.0\n"
     ]
    }
   ],
   "source": [
    "# Verify SparkContext\n",
    "print(sc)\n",
    "\n",
    "# Print Spark version\n",
    "print(sc.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c945564c-2496-4c0d-a631-fbbe62f1efa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
